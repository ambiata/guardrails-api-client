[@guardrails-ai/api-client](../README.md) / [Exports](../modules.md) / OpenAIChatCompletionPayload

# Interface: OpenAIChatCompletionPayload

**`Export`**

OpenAIChatCompletionPayload

## Table of contents

### Properties

- [maxTokens](OpenAIChatCompletionPayload.md#maxtokens)
- [messages](OpenAIChatCompletionPayload.md#messages)
- [model](OpenAIChatCompletionPayload.md#model)
- [temperature](OpenAIChatCompletionPayload.md#temperature)

## Properties

### maxTokens

• `Optional` **maxTokens**: `number`

The maximum number of tokens to generate

**`Memberof`**

OpenAIChatCompletionPayload

#### Defined in

src/models/OpenAIChatCompletionPayload.ts:44

___

### messages

• `Optional` **messages**: [`OpenAIChatCompletionPayloadMessagesInner`](OpenAIChatCompletionPayloadMessagesInner.md)[]

The messages to use for the completion

**`Memberof`**

OpenAIChatCompletionPayload

#### Defined in

src/models/OpenAIChatCompletionPayload.ts:38

___

### model

• `Optional` **model**: `string`

The model to use for the completion

**`Memberof`**

OpenAIChatCompletionPayload

#### Defined in

src/models/OpenAIChatCompletionPayload.ts:32

___

### temperature

• `Optional` **temperature**: `number`

The sampling temperature

**`Memberof`**

OpenAIChatCompletionPayload

#### Defined in

src/models/OpenAIChatCompletionPayload.ts:50
